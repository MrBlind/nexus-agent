// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.9
// 	protoc        v5.29.3
// source: llm_service.proto

package llmv1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	timestamppb "google.golang.org/protobuf/types/known/timestamppb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// 流式响应类型
type ExecuteAgentStreamResponse_StreamType int32

const (
	ExecuteAgentStreamResponse_CONTENT_DELTA  ExecuteAgentStreamResponse_StreamType = 0 // 内容增量
	ExecuteAgentStreamResponse_TOOL_CALL      ExecuteAgentStreamResponse_StreamType = 1 // 工具调用
	ExecuteAgentStreamResponse_USAGE_UPDATE   ExecuteAgentStreamResponse_StreamType = 2 // 使用量更新
	ExecuteAgentStreamResponse_FINAL_RESPONSE ExecuteAgentStreamResponse_StreamType = 3 // 最终响应
	ExecuteAgentStreamResponse_ERROR          ExecuteAgentStreamResponse_StreamType = 4 // 错误
)

// Enum value maps for ExecuteAgentStreamResponse_StreamType.
var (
	ExecuteAgentStreamResponse_StreamType_name = map[int32]string{
		0: "CONTENT_DELTA",
		1: "TOOL_CALL",
		2: "USAGE_UPDATE",
		3: "FINAL_RESPONSE",
		4: "ERROR",
	}
	ExecuteAgentStreamResponse_StreamType_value = map[string]int32{
		"CONTENT_DELTA":  0,
		"TOOL_CALL":      1,
		"USAGE_UPDATE":   2,
		"FINAL_RESPONSE": 3,
		"ERROR":          4,
	}
)

func (x ExecuteAgentStreamResponse_StreamType) Enum() *ExecuteAgentStreamResponse_StreamType {
	p := new(ExecuteAgentStreamResponse_StreamType)
	*p = x
	return p
}

func (x ExecuteAgentStreamResponse_StreamType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ExecuteAgentStreamResponse_StreamType) Descriptor() protoreflect.EnumDescriptor {
	return file_llm_service_proto_enumTypes[0].Descriptor()
}

func (ExecuteAgentStreamResponse_StreamType) Type() protoreflect.EnumType {
	return &file_llm_service_proto_enumTypes[0]
}

func (x ExecuteAgentStreamResponse_StreamType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ExecuteAgentStreamResponse_StreamType.Descriptor instead.
func (ExecuteAgentStreamResponse_StreamType) EnumDescriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{6, 0}
}

// 消息定义
type Message struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Role          string                 `protobuf:"bytes,1,opt,name=role,proto3" json:"role,omitempty"`                         // user, assistant, system
	Content       string                 `protobuf:"bytes,2,opt,name=content,proto3" json:"content,omitempty"`                   // 消息内容
	ImageUrl      string                 `protobuf:"bytes,3,opt,name=image_url,json=imageUrl,proto3" json:"image_url,omitempty"` // 可选的图片 URL
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Message) Reset() {
	*x = Message{}
	mi := &file_llm_service_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Message) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Message) ProtoMessage() {}

func (x *Message) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Message.ProtoReflect.Descriptor instead.
func (*Message) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{0}
}

func (x *Message) GetRole() string {
	if x != nil {
		return x.Role
	}
	return ""
}

func (x *Message) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *Message) GetImageUrl() string {
	if x != nil {
		return x.ImageUrl
	}
	return ""
}

// 工具调用定义
type ToolCall struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	Type          string                 `protobuf:"bytes,2,opt,name=type,proto3" json:"type,omitempty"`
	Function      *ToolFunction          `protobuf:"bytes,3,opt,name=function,proto3" json:"function,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ToolCall) Reset() {
	*x = ToolCall{}
	mi := &file_llm_service_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ToolCall) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ToolCall) ProtoMessage() {}

func (x *ToolCall) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ToolCall.ProtoReflect.Descriptor instead.
func (*ToolCall) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{1}
}

func (x *ToolCall) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *ToolCall) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *ToolCall) GetFunction() *ToolFunction {
	if x != nil {
		return x.Function
	}
	return nil
}

type ToolFunction struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Name          string                 `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	Arguments     string                 `protobuf:"bytes,2,opt,name=arguments,proto3" json:"arguments,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ToolFunction) Reset() {
	*x = ToolFunction{}
	mi := &file_llm_service_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ToolFunction) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ToolFunction) ProtoMessage() {}

func (x *ToolFunction) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ToolFunction.ProtoReflect.Descriptor instead.
func (*ToolFunction) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{2}
}

func (x *ToolFunction) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *ToolFunction) GetArguments() string {
	if x != nil {
		return x.Arguments
	}
	return ""
}

// 使用量统计
type Usage struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	PromptTokens     int32                  `protobuf:"varint,1,opt,name=prompt_tokens,json=promptTokens,proto3" json:"prompt_tokens,omitempty"`
	CompletionTokens int32                  `protobuf:"varint,2,opt,name=completion_tokens,json=completionTokens,proto3" json:"completion_tokens,omitempty"`
	TotalTokens      int32                  `protobuf:"varint,3,opt,name=total_tokens,json=totalTokens,proto3" json:"total_tokens,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *Usage) Reset() {
	*x = Usage{}
	mi := &file_llm_service_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Usage) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Usage) ProtoMessage() {}

func (x *Usage) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Usage.ProtoReflect.Descriptor instead.
func (*Usage) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{3}
}

func (x *Usage) GetPromptTokens() int32 {
	if x != nil {
		return x.PromptTokens
	}
	return 0
}

func (x *Usage) GetCompletionTokens() int32 {
	if x != nil {
		return x.CompletionTokens
	}
	return 0
}

func (x *Usage) GetTotalTokens() int32 {
	if x != nil {
		return x.TotalTokens
	}
	return 0
}

// 执行代理请求
type ExecuteAgentRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	SessionId     string                 `protobuf:"bytes,1,opt,name=session_id,json=sessionId,proto3" json:"session_id,omitempty"`
	Messages      []*Message             `protobuf:"bytes,2,rep,name=messages,proto3" json:"messages,omitempty"`
	Provider      string                 `protobuf:"bytes,3,opt,name=provider,proto3" json:"provider,omitempty"`                     // 提供商名称，如: "openai", "deepseek", "anthropic"
	Model         string                 `protobuf:"bytes,4,opt,name=model,proto3" json:"model,omitempty"`                           // 模型名称，如: "gpt-4", "deepseek-chat", "claude-3-sonnet"
	Temperature   float64                `protobuf:"fixed64,5,opt,name=temperature,proto3" json:"temperature,omitempty"`             // 可选：温度参数
	MaxTokens     int32                  `protobuf:"varint,6,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"` // 可选：最大令牌数
	Tools         []string               `protobuf:"bytes,7,rep,name=tools,proto3" json:"tools,omitempty"`                           // 可选的工具列表
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ExecuteAgentRequest) Reset() {
	*x = ExecuteAgentRequest{}
	mi := &file_llm_service_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExecuteAgentRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExecuteAgentRequest) ProtoMessage() {}

func (x *ExecuteAgentRequest) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ExecuteAgentRequest.ProtoReflect.Descriptor instead.
func (*ExecuteAgentRequest) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{4}
}

func (x *ExecuteAgentRequest) GetSessionId() string {
	if x != nil {
		return x.SessionId
	}
	return ""
}

func (x *ExecuteAgentRequest) GetMessages() []*Message {
	if x != nil {
		return x.Messages
	}
	return nil
}

func (x *ExecuteAgentRequest) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *ExecuteAgentRequest) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *ExecuteAgentRequest) GetTemperature() float64 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *ExecuteAgentRequest) GetMaxTokens() int32 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

func (x *ExecuteAgentRequest) GetTools() []string {
	if x != nil {
		return x.Tools
	}
	return nil
}

// 执行代理响应
type ExecuteAgentResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	SessionId     string                 `protobuf:"bytes,1,opt,name=session_id,json=sessionId,proto3" json:"session_id,omitempty"`
	Message       *Message               `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	Usage         *Usage                 `protobuf:"bytes,3,opt,name=usage,proto3" json:"usage,omitempty"`
	Cost          float64                `protobuf:"fixed64,4,opt,name=cost,proto3" json:"cost,omitempty"`
	ExecutionTime float64                `protobuf:"fixed64,5,opt,name=execution_time,json=executionTime,proto3" json:"execution_time,omitempty"`
	ToolCalls     []*ToolCall            `protobuf:"bytes,6,rep,name=tool_calls,json=toolCalls,proto3" json:"tool_calls,omitempty"`
	Timestamp     *timestamppb.Timestamp `protobuf:"bytes,7,opt,name=timestamp,proto3" json:"timestamp,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ExecuteAgentResponse) Reset() {
	*x = ExecuteAgentResponse{}
	mi := &file_llm_service_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExecuteAgentResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExecuteAgentResponse) ProtoMessage() {}

func (x *ExecuteAgentResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ExecuteAgentResponse.ProtoReflect.Descriptor instead.
func (*ExecuteAgentResponse) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{5}
}

func (x *ExecuteAgentResponse) GetSessionId() string {
	if x != nil {
		return x.SessionId
	}
	return ""
}

func (x *ExecuteAgentResponse) GetMessage() *Message {
	if x != nil {
		return x.Message
	}
	return nil
}

func (x *ExecuteAgentResponse) GetUsage() *Usage {
	if x != nil {
		return x.Usage
	}
	return nil
}

func (x *ExecuteAgentResponse) GetCost() float64 {
	if x != nil {
		return x.Cost
	}
	return 0
}

func (x *ExecuteAgentResponse) GetExecutionTime() float64 {
	if x != nil {
		return x.ExecutionTime
	}
	return 0
}

func (x *ExecuteAgentResponse) GetToolCalls() []*ToolCall {
	if x != nil {
		return x.ToolCalls
	}
	return nil
}

func (x *ExecuteAgentResponse) GetTimestamp() *timestamppb.Timestamp {
	if x != nil {
		return x.Timestamp
	}
	return nil
}

// 流式执行代理响应
type ExecuteAgentStreamResponse struct {
	state     protoimpl.MessageState                `protogen:"open.v1"`
	SessionId string                                `protobuf:"bytes,1,opt,name=session_id,json=sessionId,proto3" json:"session_id,omitempty"`
	Type      ExecuteAgentStreamResponse_StreamType `protobuf:"varint,2,opt,name=type,proto3,enum=nexus.llm.v1.ExecuteAgentStreamResponse_StreamType" json:"type,omitempty"`
	// 根据类型使用不同字段
	ContentDelta  string                 `protobuf:"bytes,3,opt,name=content_delta,json=contentDelta,proto3" json:"content_delta,omitempty"`      // 当 type = CONTENT_DELTA 时使用
	ToolCall      *ToolCall              `protobuf:"bytes,4,opt,name=tool_call,json=toolCall,proto3" json:"tool_call,omitempty"`                  // 当 type = TOOL_CALL 时使用
	Usage         *Usage                 `protobuf:"bytes,5,opt,name=usage,proto3" json:"usage,omitempty"`                                        // 当 type = USAGE_UPDATE 或 FINAL_RESPONSE 时使用
	Cost          float64                `protobuf:"fixed64,6,opt,name=cost,proto3" json:"cost,omitempty"`                                        // 当 type = FINAL_RESPONSE 时使用
	ExecutionTime float64                `protobuf:"fixed64,7,opt,name=execution_time,json=executionTime,proto3" json:"execution_time,omitempty"` // 当 type = FINAL_RESPONSE 时使用
	ErrorMessage  string                 `protobuf:"bytes,8,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`      // 当 type = ERROR 时使用
	Timestamp     *timestamppb.Timestamp `protobuf:"bytes,9,opt,name=timestamp,proto3" json:"timestamp,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ExecuteAgentStreamResponse) Reset() {
	*x = ExecuteAgentStreamResponse{}
	mi := &file_llm_service_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExecuteAgentStreamResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExecuteAgentStreamResponse) ProtoMessage() {}

func (x *ExecuteAgentStreamResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ExecuteAgentStreamResponse.ProtoReflect.Descriptor instead.
func (*ExecuteAgentStreamResponse) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{6}
}

func (x *ExecuteAgentStreamResponse) GetSessionId() string {
	if x != nil {
		return x.SessionId
	}
	return ""
}

func (x *ExecuteAgentStreamResponse) GetType() ExecuteAgentStreamResponse_StreamType {
	if x != nil {
		return x.Type
	}
	return ExecuteAgentStreamResponse_CONTENT_DELTA
}

func (x *ExecuteAgentStreamResponse) GetContentDelta() string {
	if x != nil {
		return x.ContentDelta
	}
	return ""
}

func (x *ExecuteAgentStreamResponse) GetToolCall() *ToolCall {
	if x != nil {
		return x.ToolCall
	}
	return nil
}

func (x *ExecuteAgentStreamResponse) GetUsage() *Usage {
	if x != nil {
		return x.Usage
	}
	return nil
}

func (x *ExecuteAgentStreamResponse) GetCost() float64 {
	if x != nil {
		return x.Cost
	}
	return 0
}

func (x *ExecuteAgentStreamResponse) GetExecutionTime() float64 {
	if x != nil {
		return x.ExecutionTime
	}
	return 0
}

func (x *ExecuteAgentStreamResponse) GetErrorMessage() string {
	if x != nil {
		return x.ErrorMessage
	}
	return ""
}

func (x *ExecuteAgentStreamResponse) GetTimestamp() *timestamppb.Timestamp {
	if x != nil {
		return x.Timestamp
	}
	return nil
}

// 获取支持的模型请求
type GetSupportedModelsRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetSupportedModelsRequest) Reset() {
	*x = GetSupportedModelsRequest{}
	mi := &file_llm_service_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetSupportedModelsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetSupportedModelsRequest) ProtoMessage() {}

func (x *GetSupportedModelsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetSupportedModelsRequest.ProtoReflect.Descriptor instead.
func (*GetSupportedModelsRequest) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{7}
}

// 提供商信息
type ProviderInfo struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Name          string                 `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	Models        []string               `protobuf:"bytes,2,rep,name=models,proto3" json:"models,omitempty"`
	DefaultModel  string                 `protobuf:"bytes,3,opt,name=default_model,json=defaultModel,proto3" json:"default_model,omitempty"`
	RequiresKey   bool                   `protobuf:"varint,4,opt,name=requires_key,json=requiresKey,proto3" json:"requires_key,omitempty"`
	Pricing       map[string]float64     `protobuf:"bytes,5,rep,name=pricing,proto3" json:"pricing,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"fixed64,2,opt,name=value"` // 模型定价信息
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ProviderInfo) Reset() {
	*x = ProviderInfo{}
	mi := &file_llm_service_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ProviderInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ProviderInfo) ProtoMessage() {}

func (x *ProviderInfo) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ProviderInfo.ProtoReflect.Descriptor instead.
func (*ProviderInfo) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{8}
}

func (x *ProviderInfo) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *ProviderInfo) GetModels() []string {
	if x != nil {
		return x.Models
	}
	return nil
}

func (x *ProviderInfo) GetDefaultModel() string {
	if x != nil {
		return x.DefaultModel
	}
	return ""
}

func (x *ProviderInfo) GetRequiresKey() bool {
	if x != nil {
		return x.RequiresKey
	}
	return false
}

func (x *ProviderInfo) GetPricing() map[string]float64 {
	if x != nil {
		return x.Pricing
	}
	return nil
}

// 获取支持的模型响应
type GetSupportedModelsResponse struct {
	state         protoimpl.MessageState   `protogen:"open.v1"`
	Providers     map[string]*ProviderInfo `protobuf:"bytes,1,rep,name=providers,proto3" json:"providers,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetSupportedModelsResponse) Reset() {
	*x = GetSupportedModelsResponse{}
	mi := &file_llm_service_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetSupportedModelsResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetSupportedModelsResponse) ProtoMessage() {}

func (x *GetSupportedModelsResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetSupportedModelsResponse.ProtoReflect.Descriptor instead.
func (*GetSupportedModelsResponse) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{9}
}

func (x *GetSupportedModelsResponse) GetProviders() map[string]*ProviderInfo {
	if x != nil {
		return x.Providers
	}
	return nil
}

// 验证配置请求
type ValidateConfigRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Provider      string                 `protobuf:"bytes,1,opt,name=provider,proto3" json:"provider,omitempty"`                     // 提供商名称
	Model         string                 `protobuf:"bytes,2,opt,name=model,proto3" json:"model,omitempty"`                           // 模型名称
	Temperature   float64                `protobuf:"fixed64,3,opt,name=temperature,proto3" json:"temperature,omitempty"`             // 温度参数
	MaxTokens     int32                  `protobuf:"varint,4,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"` // 最大令牌数
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ValidateConfigRequest) Reset() {
	*x = ValidateConfigRequest{}
	mi := &file_llm_service_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ValidateConfigRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ValidateConfigRequest) ProtoMessage() {}

func (x *ValidateConfigRequest) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ValidateConfigRequest.ProtoReflect.Descriptor instead.
func (*ValidateConfigRequest) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{10}
}

func (x *ValidateConfigRequest) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *ValidateConfigRequest) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *ValidateConfigRequest) GetTemperature() float64 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *ValidateConfigRequest) GetMaxTokens() int32 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

// 验证配置响应
type ValidateConfigResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Valid         bool                   `protobuf:"varint,1,opt,name=valid,proto3" json:"valid,omitempty"`
	ErrorMessage  string                 `protobuf:"bytes,2,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ValidateConfigResponse) Reset() {
	*x = ValidateConfigResponse{}
	mi := &file_llm_service_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ValidateConfigResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ValidateConfigResponse) ProtoMessage() {}

func (x *ValidateConfigResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ValidateConfigResponse.ProtoReflect.Descriptor instead.
func (*ValidateConfigResponse) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{11}
}

func (x *ValidateConfigResponse) GetValid() bool {
	if x != nil {
		return x.Valid
	}
	return false
}

func (x *ValidateConfigResponse) GetErrorMessage() string {
	if x != nil {
		return x.ErrorMessage
	}
	return ""
}

// 健康检查请求
type HealthCheckRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthCheckRequest) Reset() {
	*x = HealthCheckRequest{}
	mi := &file_llm_service_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthCheckRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthCheckRequest) ProtoMessage() {}

func (x *HealthCheckRequest) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthCheckRequest.ProtoReflect.Descriptor instead.
func (*HealthCheckRequest) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{12}
}

// 健康检查响应
type HealthCheckResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Status        string                 `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
	Version       string                 `protobuf:"bytes,2,opt,name=version,proto3" json:"version,omitempty"`
	Timestamp     *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=timestamp,proto3" json:"timestamp,omitempty"`
	Details       map[string]string      `protobuf:"bytes,4,rep,name=details,proto3" json:"details,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthCheckResponse) Reset() {
	*x = HealthCheckResponse{}
	mi := &file_llm_service_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthCheckResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthCheckResponse) ProtoMessage() {}

func (x *HealthCheckResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_service_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthCheckResponse.ProtoReflect.Descriptor instead.
func (*HealthCheckResponse) Descriptor() ([]byte, []int) {
	return file_llm_service_proto_rawDescGZIP(), []int{13}
}

func (x *HealthCheckResponse) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *HealthCheckResponse) GetVersion() string {
	if x != nil {
		return x.Version
	}
	return ""
}

func (x *HealthCheckResponse) GetTimestamp() *timestamppb.Timestamp {
	if x != nil {
		return x.Timestamp
	}
	return nil
}

func (x *HealthCheckResponse) GetDetails() map[string]string {
	if x != nil {
		return x.Details
	}
	return nil
}

var File_llm_service_proto protoreflect.FileDescriptor

const file_llm_service_proto_rawDesc = "" +
	"\n" +
	"\x11llm_service.proto\x12\fnexus.llm.v1\x1a\x1fgoogle/protobuf/timestamp.proto\"T\n" +
	"\aMessage\x12\x12\n" +
	"\x04role\x18\x01 \x01(\tR\x04role\x12\x18\n" +
	"\acontent\x18\x02 \x01(\tR\acontent\x12\x1b\n" +
	"\timage_url\x18\x03 \x01(\tR\bimageUrl\"f\n" +
	"\bToolCall\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x12\n" +
	"\x04type\x18\x02 \x01(\tR\x04type\x126\n" +
	"\bfunction\x18\x03 \x01(\v2\x1a.nexus.llm.v1.ToolFunctionR\bfunction\"@\n" +
	"\fToolFunction\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x1c\n" +
	"\targuments\x18\x02 \x01(\tR\targuments\"|\n" +
	"\x05Usage\x12#\n" +
	"\rprompt_tokens\x18\x01 \x01(\x05R\fpromptTokens\x12+\n" +
	"\x11completion_tokens\x18\x02 \x01(\x05R\x10completionTokens\x12!\n" +
	"\ftotal_tokens\x18\x03 \x01(\x05R\vtotalTokens\"\xf0\x01\n" +
	"\x13ExecuteAgentRequest\x12\x1d\n" +
	"\n" +
	"session_id\x18\x01 \x01(\tR\tsessionId\x121\n" +
	"\bmessages\x18\x02 \x03(\v2\x15.nexus.llm.v1.MessageR\bmessages\x12\x1a\n" +
	"\bprovider\x18\x03 \x01(\tR\bprovider\x12\x14\n" +
	"\x05model\x18\x04 \x01(\tR\x05model\x12 \n" +
	"\vtemperature\x18\x05 \x01(\x01R\vtemperature\x12\x1d\n" +
	"\n" +
	"max_tokens\x18\x06 \x01(\x05R\tmaxTokens\x12\x14\n" +
	"\x05tools\x18\a \x03(\tR\x05tools\"\xbd\x02\n" +
	"\x14ExecuteAgentResponse\x12\x1d\n" +
	"\n" +
	"session_id\x18\x01 \x01(\tR\tsessionId\x12/\n" +
	"\amessage\x18\x02 \x01(\v2\x15.nexus.llm.v1.MessageR\amessage\x12)\n" +
	"\x05usage\x18\x03 \x01(\v2\x13.nexus.llm.v1.UsageR\x05usage\x12\x12\n" +
	"\x04cost\x18\x04 \x01(\x01R\x04cost\x12%\n" +
	"\x0eexecution_time\x18\x05 \x01(\x01R\rexecutionTime\x125\n" +
	"\n" +
	"tool_calls\x18\x06 \x03(\v2\x16.nexus.llm.v1.ToolCallR\ttoolCalls\x128\n" +
	"\ttimestamp\x18\a \x01(\v2\x1a.google.protobuf.TimestampR\ttimestamp\"\x84\x04\n" +
	"\x1aExecuteAgentStreamResponse\x12\x1d\n" +
	"\n" +
	"session_id\x18\x01 \x01(\tR\tsessionId\x12G\n" +
	"\x04type\x18\x02 \x01(\x0e23.nexus.llm.v1.ExecuteAgentStreamResponse.StreamTypeR\x04type\x12#\n" +
	"\rcontent_delta\x18\x03 \x01(\tR\fcontentDelta\x123\n" +
	"\ttool_call\x18\x04 \x01(\v2\x16.nexus.llm.v1.ToolCallR\btoolCall\x12)\n" +
	"\x05usage\x18\x05 \x01(\v2\x13.nexus.llm.v1.UsageR\x05usage\x12\x12\n" +
	"\x04cost\x18\x06 \x01(\x01R\x04cost\x12%\n" +
	"\x0eexecution_time\x18\a \x01(\x01R\rexecutionTime\x12#\n" +
	"\rerror_message\x18\b \x01(\tR\ferrorMessage\x128\n" +
	"\ttimestamp\x18\t \x01(\v2\x1a.google.protobuf.TimestampR\ttimestamp\"_\n" +
	"\n" +
	"StreamType\x12\x11\n" +
	"\rCONTENT_DELTA\x10\x00\x12\r\n" +
	"\tTOOL_CALL\x10\x01\x12\x10\n" +
	"\fUSAGE_UPDATE\x10\x02\x12\x12\n" +
	"\x0eFINAL_RESPONSE\x10\x03\x12\t\n" +
	"\x05ERROR\x10\x04\"\x1b\n" +
	"\x19GetSupportedModelsRequest\"\x81\x02\n" +
	"\fProviderInfo\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x16\n" +
	"\x06models\x18\x02 \x03(\tR\x06models\x12#\n" +
	"\rdefault_model\x18\x03 \x01(\tR\fdefaultModel\x12!\n" +
	"\frequires_key\x18\x04 \x01(\bR\vrequiresKey\x12A\n" +
	"\apricing\x18\x05 \x03(\v2'.nexus.llm.v1.ProviderInfo.PricingEntryR\apricing\x1a:\n" +
	"\fPricingEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x01R\x05value:\x028\x01\"\xcd\x01\n" +
	"\x1aGetSupportedModelsResponse\x12U\n" +
	"\tproviders\x18\x01 \x03(\v27.nexus.llm.v1.GetSupportedModelsResponse.ProvidersEntryR\tproviders\x1aX\n" +
	"\x0eProvidersEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x120\n" +
	"\x05value\x18\x02 \x01(\v2\x1a.nexus.llm.v1.ProviderInfoR\x05value:\x028\x01\"\x8a\x01\n" +
	"\x15ValidateConfigRequest\x12\x1a\n" +
	"\bprovider\x18\x01 \x01(\tR\bprovider\x12\x14\n" +
	"\x05model\x18\x02 \x01(\tR\x05model\x12 \n" +
	"\vtemperature\x18\x03 \x01(\x01R\vtemperature\x12\x1d\n" +
	"\n" +
	"max_tokens\x18\x04 \x01(\x05R\tmaxTokens\"S\n" +
	"\x16ValidateConfigResponse\x12\x14\n" +
	"\x05valid\x18\x01 \x01(\bR\x05valid\x12#\n" +
	"\rerror_message\x18\x02 \x01(\tR\ferrorMessage\"\x14\n" +
	"\x12HealthCheckRequest\"\x87\x02\n" +
	"\x13HealthCheckResponse\x12\x16\n" +
	"\x06status\x18\x01 \x01(\tR\x06status\x12\x18\n" +
	"\aversion\x18\x02 \x01(\tR\aversion\x128\n" +
	"\ttimestamp\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\ttimestamp\x12H\n" +
	"\adetails\x18\x04 \x03(\v2..nexus.llm.v1.HealthCheckResponse.DetailsEntryR\adetails\x1a:\n" +
	"\fDetailsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x012\xe2\x03\n" +
	"\n" +
	"LLMService\x12U\n" +
	"\fExecuteAgent\x12!.nexus.llm.v1.ExecuteAgentRequest\x1a\".nexus.llm.v1.ExecuteAgentResponse\x12c\n" +
	"\x12ExecuteAgentStream\x12!.nexus.llm.v1.ExecuteAgentRequest\x1a(.nexus.llm.v1.ExecuteAgentStreamResponse0\x01\x12g\n" +
	"\x12GetSupportedModels\x12'.nexus.llm.v1.GetSupportedModelsRequest\x1a(.nexus.llm.v1.GetSupportedModelsResponse\x12[\n" +
	"\x0eValidateConfig\x12#.nexus.llm.v1.ValidateConfigRequest\x1a$.nexus.llm.v1.ValidateConfigResponse\x12R\n" +
	"\vHealthCheck\x12 .nexus.llm.v1.HealthCheckRequest\x1a!.nexus.llm.v1.HealthCheckResponseB3Z1github.com/mrblind/nexus-agent/proto/llm/v1;llmv1b\x06proto3"

var (
	file_llm_service_proto_rawDescOnce sync.Once
	file_llm_service_proto_rawDescData []byte
)

func file_llm_service_proto_rawDescGZIP() []byte {
	file_llm_service_proto_rawDescOnce.Do(func() {
		file_llm_service_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_llm_service_proto_rawDesc), len(file_llm_service_proto_rawDesc)))
	})
	return file_llm_service_proto_rawDescData
}

var file_llm_service_proto_enumTypes = make([]protoimpl.EnumInfo, 1)
var file_llm_service_proto_msgTypes = make([]protoimpl.MessageInfo, 17)
var file_llm_service_proto_goTypes = []any{
	(ExecuteAgentStreamResponse_StreamType)(0), // 0: nexus.llm.v1.ExecuteAgentStreamResponse.StreamType
	(*Message)(nil),                    // 1: nexus.llm.v1.Message
	(*ToolCall)(nil),                   // 2: nexus.llm.v1.ToolCall
	(*ToolFunction)(nil),               // 3: nexus.llm.v1.ToolFunction
	(*Usage)(nil),                      // 4: nexus.llm.v1.Usage
	(*ExecuteAgentRequest)(nil),        // 5: nexus.llm.v1.ExecuteAgentRequest
	(*ExecuteAgentResponse)(nil),       // 6: nexus.llm.v1.ExecuteAgentResponse
	(*ExecuteAgentStreamResponse)(nil), // 7: nexus.llm.v1.ExecuteAgentStreamResponse
	(*GetSupportedModelsRequest)(nil),  // 8: nexus.llm.v1.GetSupportedModelsRequest
	(*ProviderInfo)(nil),               // 9: nexus.llm.v1.ProviderInfo
	(*GetSupportedModelsResponse)(nil), // 10: nexus.llm.v1.GetSupportedModelsResponse
	(*ValidateConfigRequest)(nil),      // 11: nexus.llm.v1.ValidateConfigRequest
	(*ValidateConfigResponse)(nil),     // 12: nexus.llm.v1.ValidateConfigResponse
	(*HealthCheckRequest)(nil),         // 13: nexus.llm.v1.HealthCheckRequest
	(*HealthCheckResponse)(nil),        // 14: nexus.llm.v1.HealthCheckResponse
	nil,                                // 15: nexus.llm.v1.ProviderInfo.PricingEntry
	nil,                                // 16: nexus.llm.v1.GetSupportedModelsResponse.ProvidersEntry
	nil,                                // 17: nexus.llm.v1.HealthCheckResponse.DetailsEntry
	(*timestamppb.Timestamp)(nil),      // 18: google.protobuf.Timestamp
}
var file_llm_service_proto_depIdxs = []int32{
	3,  // 0: nexus.llm.v1.ToolCall.function:type_name -> nexus.llm.v1.ToolFunction
	1,  // 1: nexus.llm.v1.ExecuteAgentRequest.messages:type_name -> nexus.llm.v1.Message
	1,  // 2: nexus.llm.v1.ExecuteAgentResponse.message:type_name -> nexus.llm.v1.Message
	4,  // 3: nexus.llm.v1.ExecuteAgentResponse.usage:type_name -> nexus.llm.v1.Usage
	2,  // 4: nexus.llm.v1.ExecuteAgentResponse.tool_calls:type_name -> nexus.llm.v1.ToolCall
	18, // 5: nexus.llm.v1.ExecuteAgentResponse.timestamp:type_name -> google.protobuf.Timestamp
	0,  // 6: nexus.llm.v1.ExecuteAgentStreamResponse.type:type_name -> nexus.llm.v1.ExecuteAgentStreamResponse.StreamType
	2,  // 7: nexus.llm.v1.ExecuteAgentStreamResponse.tool_call:type_name -> nexus.llm.v1.ToolCall
	4,  // 8: nexus.llm.v1.ExecuteAgentStreamResponse.usage:type_name -> nexus.llm.v1.Usage
	18, // 9: nexus.llm.v1.ExecuteAgentStreamResponse.timestamp:type_name -> google.protobuf.Timestamp
	15, // 10: nexus.llm.v1.ProviderInfo.pricing:type_name -> nexus.llm.v1.ProviderInfo.PricingEntry
	16, // 11: nexus.llm.v1.GetSupportedModelsResponse.providers:type_name -> nexus.llm.v1.GetSupportedModelsResponse.ProvidersEntry
	18, // 12: nexus.llm.v1.HealthCheckResponse.timestamp:type_name -> google.protobuf.Timestamp
	17, // 13: nexus.llm.v1.HealthCheckResponse.details:type_name -> nexus.llm.v1.HealthCheckResponse.DetailsEntry
	9,  // 14: nexus.llm.v1.GetSupportedModelsResponse.ProvidersEntry.value:type_name -> nexus.llm.v1.ProviderInfo
	5,  // 15: nexus.llm.v1.LLMService.ExecuteAgent:input_type -> nexus.llm.v1.ExecuteAgentRequest
	5,  // 16: nexus.llm.v1.LLMService.ExecuteAgentStream:input_type -> nexus.llm.v1.ExecuteAgentRequest
	8,  // 17: nexus.llm.v1.LLMService.GetSupportedModels:input_type -> nexus.llm.v1.GetSupportedModelsRequest
	11, // 18: nexus.llm.v1.LLMService.ValidateConfig:input_type -> nexus.llm.v1.ValidateConfigRequest
	13, // 19: nexus.llm.v1.LLMService.HealthCheck:input_type -> nexus.llm.v1.HealthCheckRequest
	6,  // 20: nexus.llm.v1.LLMService.ExecuteAgent:output_type -> nexus.llm.v1.ExecuteAgentResponse
	7,  // 21: nexus.llm.v1.LLMService.ExecuteAgentStream:output_type -> nexus.llm.v1.ExecuteAgentStreamResponse
	10, // 22: nexus.llm.v1.LLMService.GetSupportedModels:output_type -> nexus.llm.v1.GetSupportedModelsResponse
	12, // 23: nexus.llm.v1.LLMService.ValidateConfig:output_type -> nexus.llm.v1.ValidateConfigResponse
	14, // 24: nexus.llm.v1.LLMService.HealthCheck:output_type -> nexus.llm.v1.HealthCheckResponse
	20, // [20:25] is the sub-list for method output_type
	15, // [15:20] is the sub-list for method input_type
	15, // [15:15] is the sub-list for extension type_name
	15, // [15:15] is the sub-list for extension extendee
	0,  // [0:15] is the sub-list for field type_name
}

func init() { file_llm_service_proto_init() }
func file_llm_service_proto_init() {
	if File_llm_service_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_llm_service_proto_rawDesc), len(file_llm_service_proto_rawDesc)),
			NumEnums:      1,
			NumMessages:   17,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_llm_service_proto_goTypes,
		DependencyIndexes: file_llm_service_proto_depIdxs,
		EnumInfos:         file_llm_service_proto_enumTypes,
		MessageInfos:      file_llm_service_proto_msgTypes,
	}.Build()
	File_llm_service_proto = out.File
	file_llm_service_proto_goTypes = nil
	file_llm_service_proto_depIdxs = nil
}
