#!/usr/bin/env python3
"""
LLM æ¨¡å‹åˆ‡æ¢æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•åœ¨å®é™…é¡¹ç›®ä¸­ä¸€è¡Œä»£ç åˆ‡æ¢æ¨¡å‹
"""

import os
import asyncio
from src.core.model_factory import create_openai_engine, create_deepseek_engine
from src.models.request import Message, AgentExecuteRequest


async def demo_model_switching():
    """æ¼”ç¤ºæ¨¡å‹åˆ‡æ¢åŠŸèƒ½"""
    print("ğŸš€ LLM æ¨¡å‹åˆ‡æ¢æ¼”ç¤º")
    print("=" * 50)
    
    # å‡†å¤‡æµ‹è¯•æ¶ˆæ¯
    messages = [
        Message(role="user", content="è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ï¼Œå¹¶è¯´æ˜ä½ çš„ä¼˜åŠ¿ã€‚")
    ]
    
    request = AgentExecuteRequest(
        session_id="demo-session",
        messages=messages,
        temperature=0.7,
        max_tokens=100
    )
    
    # æ£€æŸ¥ API å¯†é’¥
    openai_key = os.getenv("OPENAI_API_KEY")
    deepseek_key = os.getenv("DEEPSEEK_API_KEY")
    
    if not openai_key and not deepseek_key:
        print("âš ï¸  è¯·è®¾ç½®ç¯å¢ƒå˜é‡:")
        print("   export OPENAI_API_KEY='your-openai-key'")
        print("   export DEEPSEEK_API_KEY='your-deepseek-key'")
        print("\nğŸ’¡ æ¼”ç¤ºæ¨¡å‹åˆ›å»ºï¼ˆä¸å‘é€è¯·æ±‚ï¼‰:")
        
        # æ¼”ç¤ºæ¨¡å‹åˆ›å»º
        print("\n1ï¸âƒ£  åˆ›å»º OpenAI å¼•æ“:")
        print("   agent = create_openai_engine(api_key='your-key')")
        openai_agent = create_openai_engine(api_key="demo-key")
        print(f"   âœ… åˆ›å»ºæˆåŠŸ: {openai_agent.default_model}")
        
        print("\n2ï¸âƒ£  åˆ‡æ¢åˆ° DeepSeekï¼ˆåªéœ€ä¿®æ”¹ä¸€è¡Œï¼‰:")
        print("   agent = create_deepseek_engine(api_key='your-key')")
        deepseek_agent = create_deepseek_engine(api_key="demo-key")
        print(f"   âœ… åˆ›å»ºæˆåŠŸ: {deepseek_agent.default_model}")
        
        print("\nğŸ¯ å°±æ˜¯è¿™ä¹ˆç®€å•ï¼ä¸€è¡Œä»£ç åˆ‡æ¢æ¨¡å‹ï¼")
        return
    
    # å®é™… API è°ƒç”¨æ¼”ç¤º
    print("ğŸ”¥ å®é™… API è°ƒç”¨æ¼”ç¤º:")
    
    if openai_key:
        print("\n1ï¸âƒ£  ä½¿ç”¨ OpenAI:")
        print("   agent = create_openai_engine(api_key)")
        
        try:
            # ä¸€è¡Œä»£ç åˆ›å»º OpenAI å¼•æ“
            agent = create_openai_engine(api_key=openai_key, model="gpt-3.5-turbo")
            
            response = await agent.execute_agent(request)
            print(f"   ğŸ“ å“åº”: {response.message.content}")
            print(f"   ğŸ’° æˆæœ¬: ${response.cost:.6f}")
            print(f"   â±ï¸  è€—æ—¶: {response.execution_time:.2f}s")
            
        except Exception as e:
            print(f"   âŒ OpenAI è°ƒç”¨å¤±è´¥: {e}")
    
    if deepseek_key:
        print("\n2ï¸âƒ£  åˆ‡æ¢åˆ° DeepSeekï¼ˆåªéœ€ä¿®æ”¹ä¸€è¡Œï¼‰:")
        print("   agent = create_deepseek_engine(api_key)")
        
        try:
            # ä¸€è¡Œä»£ç åˆ‡æ¢åˆ° DeepSeek å¼•æ“
            agent = create_deepseek_engine(api_key=deepseek_key)
            
            response = await agent.execute_agent(request)
            print(f"   ğŸ“ å“åº”: {response.message.content}")
            print(f"   ğŸ’° æˆæœ¬: ${response.cost:.6f}")
            print(f"   â±ï¸  è€—æ—¶: {response.execution_time:.2f}s")
            
        except Exception as e:
            print(f"   âŒ DeepSeek è°ƒç”¨å¤±è´¥: {e}")
    
    print("\n" + "=" * 50)
    print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ å…³é”®ä¼˜åŠ¿:")
    print("   â€¢ ä¸€è¡Œä»£ç åˆ‡æ¢æ¨¡å‹")
    print("   â€¢ ç»Ÿä¸€çš„æ¥å£ï¼Œæ— éœ€ä¿®æ”¹ä¸šåŠ¡é€»è¾‘")
    print("   â€¢ æ˜“äºæ‰©å±•æ–°çš„ LLM æä¾›å•†")
    print("   â€¢ æ”¯æŒè¿è¡Œæ—¶åŠ¨æ€åˆ‡æ¢")


def show_usage_examples():
    """æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹"""
    print("\nğŸ“š ä½¿ç”¨ç¤ºä¾‹:")
    print("-" * 30)
    
    print("\nğŸ”§ æ–¹æ³•ä¸€ï¼šç›´æ¥åˆ‡æ¢")
    print("""
# ä½¿ç”¨ OpenAI
agent = create_openai_engine(api_key="your-openai-key")

# åˆ‡æ¢åˆ° DeepSeekï¼ˆåªéœ€ä¿®æ”¹è¿™ä¸€è¡Œï¼‰
agent = create_deepseek_engine(api_key="your-deepseek-key")
""")
    
    print("ğŸ”§ æ–¹æ³•äºŒï¼šå·¥å‚æ¨¡å¼")
    print("""
from src.core.model_factory import ModelFactory

# ä½¿ç”¨ OpenAI
agent = ModelFactory.create_engine("openai", api_key="your-key")

# åˆ‡æ¢åˆ° DeepSeek
agent = ModelFactory.create_engine("deepseek", api_key="your-key")
""")
    
    print("ğŸ”§ æ–¹æ³•ä¸‰ï¼šç»Ÿä¸€å®¢æˆ·ç«¯")
    print("""
from src.core.unified_llm_client import UnifiedLLMClient

# åˆ›å»ºå®¢æˆ·ç«¯
client = UnifiedLLMClient(config)

# è¿è¡Œæ—¶åˆ‡æ¢
client.switch_engine("deepseek", api_key="your-key")
""")


if __name__ == "__main__":
    try:
        asyncio.run(demo_model_switching())
        show_usage_examples()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æ¼”ç¤ºå·²å–æ¶ˆ")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…å®Œæ•´: pip install -r requirements.txt")
